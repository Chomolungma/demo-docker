{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting Started with GOAI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading data into a GPU DataFrame (GDF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading data into a Pandas DataFrame\n",
    "\n",
    "It's easy to load almost any sort of data (json, csv, etc) into a Pandas DataFrame. Ex (csv import from disk):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas\n",
    "\n",
    "# read data from csv file into pandas dataframe\n",
    "df = pandas.read_csv('data/ipums/ipums_easy.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Read more on using a Pandas DataFrame](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Converting a Pandas DataFrame to a GDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pygdf\n",
    "\n",
    "# convert the panda dataframe into a gpu dataframe\n",
    "gdf = pygdf.DataFrame.from_pandas(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working with the GDF\n",
    "See the [pygdf documentation](http://pygdf.readthedocs.io/en/latest/index.html) for more."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Take a look at the columns and their data types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RECTYPE          int64\n",
       "YEAR             int64\n",
       "DATANUM          int64\n",
       "SERIAL           int64\n",
       "NUMPREC          int64\n",
       "SUBSAMP          int64\n",
       "HHWT             int64\n",
       "HHTYPE           int64\n",
       "REPWT          float64\n",
       "CLUSTER          int64\n",
       "ADJUST         float64\n",
       "CPI99          float64\n",
       "REGION           int64\n",
       "STATEICP         int64\n",
       "STATEFIP         int64\n",
       "COUNTY         float64\n",
       "COUNTYFIPS     float64\n",
       "METRO          float64\n",
       "METAREA        float64\n",
       "METAREAD       float64\n",
       "MET2013        float64\n",
       "MET2013ERR     float64\n",
       "CITY           float64\n",
       "CITYERR        float64\n",
       "CITYPOP        float64\n",
       "PUMA           float64\n",
       "PUMARES2MIG    float64\n",
       "STRATA           int64\n",
       "PUMASUPR       float64\n",
       "CONSPUMA       float64\n",
       "                ...   \n",
       "REPWTP51       float64\n",
       "REPWTP52       float64\n",
       "REPWTP53       float64\n",
       "REPWTP54       float64\n",
       "REPWTP55       float64\n",
       "REPWTP56       float64\n",
       "REPWTP57       float64\n",
       "REPWTP58       float64\n",
       "REPWTP59       float64\n",
       "REPWTP60       float64\n",
       "REPWTP61       float64\n",
       "REPWTP62       float64\n",
       "REPWTP63       float64\n",
       "REPWTP64       float64\n",
       "REPWTP65       float64\n",
       "REPWTP66       float64\n",
       "REPWTP67       float64\n",
       "REPWTP68       float64\n",
       "REPWTP69       float64\n",
       "REPWTP70       float64\n",
       "REPWTP71       float64\n",
       "REPWTP72       float64\n",
       "REPWTP73       float64\n",
       "REPWTP74       float64\n",
       "REPWTP75       float64\n",
       "REPWTP76       float64\n",
       "REPWTP77       float64\n",
       "REPWTP78       float64\n",
       "REPWTP79       float64\n",
       "REPWTP80       float64\n",
       "Length: 459, dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print the columns and their datatypes in this gdf\n",
    "gdf.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Slice the GDF\n",
    "\n",
    "Woah! This GDF has a lot of columns, let's make it more manageable..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "  INCEARN PERWT   ADJUST STATEICP ROOMS BEDROOMS PHONE VEHICLES RACE  SEX  AGE VETSTAT\n",
       "0    4000   618 1.018516       21     7        4     2        3    1    2   66       1\n",
       "1   36700   684 1.018516       21     7        4     2        3    1    1   40       1\n",
       "2   54000   618 1.018516       49     5        4     2        3    1    1   51       2\n",
       "3     900   609 1.018516       49     5        4     2        3    1    2   48       1\n",
       "4    2000   621 1.018516       49     5        4     2        3    1    1   19       1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# only select certain columns (and overwrite the gdf)\n",
    "gdf = gdf.loc[0:, [\n",
    "    'INCEARN', 'PERWT', 'ADJUST', 'STATEICP', 'ROOMS', 'BEDROOMS',\n",
    "     'PHONE', 'VEHICLES', 'RACE', 'SEX', 'AGE', 'VETSTAT'\n",
    "]]\n",
    "\n",
    "# show the first 5 records of each column\n",
    "gdf.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modify data types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "INCEARN       int64\n",
       "PERWT         int64\n",
       "ADJUST      float64\n",
       "STATEICP      int64\n",
       "ROOMS         int64\n",
       "BEDROOMS      int64\n",
       "PHONE         int64\n",
       "VEHICLES      int64\n",
       "RACE          int64\n",
       "SEX           int64\n",
       "AGE           int64\n",
       "VETSTAT       int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gdf.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like `INCEARN` and `PERWT` are integers when they should be floats. Let's fix that..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "INCEARN     float64\n",
       "PERWT       float64\n",
       "ADJUST      float64\n",
       "STATEICP      int64\n",
       "ROOMS         int64\n",
       "BEDROOMS      int64\n",
       "PHONE         int64\n",
       "VEHICLES      int64\n",
       "RACE          int64\n",
       "SEX           int64\n",
       "AGE           int64\n",
       "VETSTAT       int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# force float64 instead of int64\n",
    "gdf['INCEARN'] = gdf['INCEARN'].astype(np.float64)\n",
    "gdf['PERWT'] = gdf['PERWT'].astype(np.float64)\n",
    "\n",
    "# take another look\n",
    "gdf.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Manipulate data with a user-defined function (UDF)\n",
    "\n",
    "`INCEARN` is not a true representation of income earned. Let's adjust it by multiplying it by the `ADJUST` constant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18637.0999154208"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define a function to adjust the incearn var\n",
    "# so it more accurately represents income earned\n",
    "adjust = gdf['ADJUST'][0]\n",
    "def adjust_incearn(incearn):\n",
    "    return adjust * incearn;\n",
    "\n",
    "# apply it to the 'population' column\n",
    "gdf['INCEARN'] = gdf['INCEARN'].applymap(adjust_incearn)\n",
    "\n",
    "# drop the ADJUST column\n",
    "gdf.drop_column('ADJUST')\n",
    "\n",
    "# compute the mean\n",
    "gdf['INCEARN'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sort the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "        INCEARN PERWT STATEICP ROOMS BEDROOMS PHONE VEHICLES RACE  SEX  AGE VETSTAT\n",
       "0 -10184.141484 538.0       53     4        3     2        2    1    1   35       1\n",
       "1 -10184.141484 614.0       71     7        4     2        2    5    2   57       1\n",
       "2 -10184.141484 511.0       45     9        5     2        2    1    2   48       1\n",
       "3 -10184.141484 453.0       45     9        5     2        2    1    1   57       1\n",
       "4 -10184.141484 593.0       53     9        5     2        5    1    2   55       1"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sort the gdf by the INCEARN column\n",
    "gdf = gdf.sort_values(by='INCEARN', ascending=True)\n",
    "# reset the index so we can use loc slicing later\n",
    "gdf = gdf.reset_index()\n",
    "gdf.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like we have some negative income values. Let's filter those out...\n",
    "\n",
    "### Filter the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000 = Original # of records\n",
      "9985 = New # of records\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "  INCEARN PERWT STATEICP ROOMS BEDROOMS PHONE VEHICLES RACE  SEX  AGE VETSTAT\n",
       "15     0.0 559.0       49     5        4     2        3    1    2   17       1\n",
       "16     0.0 589.0       43     8        4     2        3    1    1   21       1\n",
       "17     0.0 617.0       43     5        3     2        1    1    2   66       1\n",
       "18     0.0 574.0       43     6        4     2        1    1    1   80       2\n",
       "19     0.0 616.0       43     6        4     2        1    1    2   72       1"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# how many records do we have?\n",
    "print(\"{} = Original # of records\".format(len(gdf)))\n",
    "\n",
    "# filter out\n",
    "gdf = gdf.query('INCEARN >= 0')\n",
    "\n",
    "# how many records do we have left?\n",
    "print(\"{} = New # of records\".format(len(gdf)))\n",
    "\n",
    "# sanity check...\n",
    "gdf.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One hot encode categorical columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "INCEARN        float64\n",
       "PERWT          float64\n",
       "ROOMS            int64\n",
       "BEDROOMS         int64\n",
       "PHONE            int64\n",
       "VEHICLES         int64\n",
       "AGE              int64\n",
       "VETSTAT_1      float64\n",
       "VETSTAT_2      float64\n",
       "STATEICP_2     float64\n",
       "STATEICP_3     float64\n",
       "STATEICP_4     float64\n",
       "STATEICP_5     float64\n",
       "STATEICP_6     float64\n",
       "STATEICP_11    float64\n",
       "STATEICP_12    float64\n",
       "STATEICP_13    float64\n",
       "STATEICP_14    float64\n",
       "STATEICP_21    float64\n",
       "STATEICP_22    float64\n",
       "STATEICP_23    float64\n",
       "STATEICP_24    float64\n",
       "STATEICP_25    float64\n",
       "STATEICP_31    float64\n",
       "STATEICP_32    float64\n",
       "STATEICP_33    float64\n",
       "STATEICP_34    float64\n",
       "STATEICP_35    float64\n",
       "STATEICP_36    float64\n",
       "STATEICP_37    float64\n",
       "                ...   \n",
       "STATEICP_48    float64\n",
       "STATEICP_49    float64\n",
       "STATEICP_51    float64\n",
       "STATEICP_52    float64\n",
       "STATEICP_53    float64\n",
       "STATEICP_54    float64\n",
       "STATEICP_56    float64\n",
       "STATEICP_61    float64\n",
       "STATEICP_62    float64\n",
       "STATEICP_63    float64\n",
       "STATEICP_64    float64\n",
       "STATEICP_65    float64\n",
       "STATEICP_66    float64\n",
       "STATEICP_67    float64\n",
       "STATEICP_68    float64\n",
       "STATEICP_71    float64\n",
       "STATEICP_72    float64\n",
       "STATEICP_73    float64\n",
       "STATEICP_81    float64\n",
       "STATEICP_82    float64\n",
       "STATEICP_98    float64\n",
       "RACE_2         float64\n",
       "RACE_3         float64\n",
       "RACE_4         float64\n",
       "RACE_5         float64\n",
       "RACE_6         float64\n",
       "RACE_7         float64\n",
       "RACE_8         float64\n",
       "RACE_9         float64\n",
       "SEX_2          float64\n",
       "Length: 68, dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define the categorical columns\n",
    "cat_cols = set(['STATEICP', 'RACE', 'SEX', 'VETSTAT'])\n",
    "# store the unique values for each category column\n",
    "uniques = {}\n",
    "\n",
    "# iterate through each categorical column and one-hot\n",
    "# encode it using the unique values it has\n",
    "for k in cat_cols:\n",
    "    uniques[k] = gdf[k].unique_k(k=1000)\n",
    "    cats = uniques[k][1:]  # drop first\n",
    "    gdf = gdf.one_hot_encoding(k, prefix=k, cats=cats)\n",
    "    del gdf[k]\n",
    "    \n",
    "# we should see many more columns since the categorical\n",
    "# columns will get expanded due to one-hot encoding\n",
    "gdf.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split the data into training, validation, and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "splitpoint: 0.8 of 9985 is 7988\n",
      "gdfs[\"train\"] has 7974 rows\n",
      "gdfs[\"valid\"] has 2012 rows\n"
     ]
    }
   ],
   "source": [
    "# enforce float64 data type on ALL columns\n",
    "for k in gdf.columns:\n",
    "    gdf[k] = gdf[k].astype(np.float64)\n",
    "\n",
    "# set the fractions for training and validation\n",
    "fractions = {\n",
    "    \"train\": 0.8,\n",
    "    \"valid\": 0.2\n",
    "}\n",
    "\n",
    "# validation splitpoint\n",
    "splitpoint = int(len(gdf) * fractions[\"train\"])\n",
    "print('splitpoint: {} of {} is {}'.format(fractions[\"train\"], len(gdf), splitpoint))\n",
    "\n",
    "# break the gdf up into training, validation, and test sets\n",
    "gdfs = {\n",
    "    \"train\": gdf.loc[:splitpoint],\n",
    "    \"valid\": gdf.loc[splitpoint:]\n",
    "}\n",
    "print('gdfs[\"train\"] has {} rows'.format(len(gdfs[\"train\"])))\n",
    "print('gdfs[\"valid\"] has {} rows'.format(len(gdfs[\"valid\"])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Turn the GDFs into matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "matrices[\"train\"][\"x\"] shape: (7974, 67)\n",
      "matrices[\"train\"][\"y\"] shape: (7974, 1)\n",
      "matrices[\"valid\"][\"x\"] shape: (2012, 67)\n",
      "matrices[\"valid\"][\"y\"] shape: (2012, 1)\n"
     ]
    }
   ],
   "source": [
    "# produce gpu matrices (to input to ml libraries, etc)\n",
    "# this step should not be necessary in the near future\n",
    "# (should be able to use gdf as input)\n",
    "matrices = {\n",
    "    \"train\": {\n",
    "        \"x\": gdfs[\"train\"].as_gpu_matrix(columns=gdf.columns[1:]),\n",
    "        \"y\": gdfs[\"train\"].as_gpu_matrix(columns=[gdf.columns[0]])\n",
    "    },\n",
    "    \"valid\": {\n",
    "        \"x\": gdfs[\"valid\"].as_gpu_matrix(columns=gdf.columns[1:]),\n",
    "        \"y\": gdfs[\"valid\"].as_gpu_matrix(columns=[gdf.columns[0]])\n",
    "    }\n",
    "}\n",
    "\n",
    "# check the matrix shapes (sanity check)\n",
    "print('matrices[\"train\"][\"x\"] shape:', matrices[\"train\"][\"x\"].shape)\n",
    "print('matrices[\"train\"][\"y\"] shape:', matrices[\"train\"][\"y\"].shape)\n",
    "print('matrices[\"valid\"][\"x\"] shape:', matrices[\"valid\"][\"x\"].shape)\n",
    "print('matrices[\"valid\"][\"y\"] shape:', matrices[\"valid\"][\"y\"].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obtain pointers to the matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# get pointers (so we can keep data on gpu)\n",
    "# this step should not be necessary in the near future\n",
    "# (should be able to use gdf as input)\n",
    "\n",
    "from ctypes import *\n",
    "\n",
    "def get_pointer(matrix):\n",
    "    return c_void_p(matrix.device_ctypes_pointer.value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train a model with H2O4GPU\n",
    "See the [H2O4GPU README](https://github.com/h2oai/h2o4gpu) for more."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up an ElasticNet model\n",
    "\n",
    "See [elastic_net.py](https://github.com/h2oai/h2o4gpu/blob/master/src/interface_py/h2o4gpu/solvers/elastic_net.py) for more documentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# uncomment the following to see documentation\n",
    "# (especially for available params)\n",
    "\n",
    "# h2o4gpu.ElasticNetH2O?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<h2o4gpu.solvers.elastic_net.ElasticNetH2O at 0x7fdfb003e860>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import h2o4gpu\n",
    "\n",
    "# set up the solver\n",
    "model = h2o4gpu.ElasticNetH2O(\n",
    "    double_precision = 1,                         # double precision to use (float64)\n",
    "    order = 'c',                                  # order of data (c = column, r = row)\n",
    "    n_gpus = 1,                                   # number of gpus to use\n",
    "    n_threads = 1,                                # 1 thread per gpu is optimal\n",
    "    family = \"elasticnet\",                        # use \"logistic\" for classification, \"elasticnet\" for regression\n",
    "    n_folds = 5,                                  # number of cross-validation folds (default is 1)\n",
    "    n_alphas = 8                                  # number of alphas to be used in search (default is 5)\n",
    ")\n",
    "\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit and predict the ElasticNet model\n",
    "\n",
    "The following will fit and predict the model. Alternative methods are available to split up fitting and predicting.\n",
    "\n",
    "`model.fit_ptr` - fitting with pointer inputs\n",
    "\n",
    "`model.fit` - fitting with numpy array inputs (does not use gpu mem currently)\n",
    "\n",
    "`model.predict_ptr` - predicting with pointer inputs\n",
    "\n",
    "`model.predict` - predicting with numpy array inputs (does not use gpu mem currently)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# uncomment the following to see documentation\n",
    "# (especially for available params)\n",
    "\n",
    "# model.fit_predict_ptr?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE per alpha value (-1.00 = missing)\n",
      "\n",
      "|   Alphas |   Train |       CV |    Valid |\n",
      "|---------:|--------:|---------:|---------:|\n",
      "|     0.00 | 5181.31 | 24937.40 | 84390.10 |\n",
      "|     0.14 | 5181.31 | 24937.40 | 84390.10 |\n",
      "|     0.29 | 5181.31 | 24937.40 | 84390.10 |\n",
      "|     0.43 | 5181.31 | 24937.40 | 84390.10 |\n",
      "|     0.57 | 5181.31 | 24937.40 | 84390.10 |\n",
      "|     0.71 | 5181.32 | 24937.40 | 84390.11 |\n",
      "|     0.86 | 5181.32 | 24937.40 | 84390.11 |\n",
      "|     1.00 | 5181.32 | 24937.41 | 84390.11 |\n"
     ]
    }
   ],
   "source": [
    "# fit the model\n",
    "train_shape = matrices[\"train\"][\"x\"].shape\n",
    "valid_shape = matrices[\"valid\"][\"x\"].shape\n",
    "nada_pointer = c_void_p(0)\n",
    "predictions = model.fit_predict_ptr(\n",
    "    double_precision = 1,                         # double precision to use (float64)\n",
    "    order = 'c',                                  # order of data (c = column, r = row)\n",
    "    m_train = train_shape[0],                     # number of rows in training set\n",
    "    n = train_shape[1],                           # number of columns in training set\n",
    "    m_valid = valid_shape[0],                     # number of rows in validation set\n",
    "    a = get_pointer(matrices[\"train\"][\"x\"]),      # pointer to training features matrix\n",
    "    b = get_pointer(matrices[\"train\"][\"y\"]),      # pointer to training response matrix\n",
    "    c = get_pointer(matrices[\"valid\"][\"x\"]),      # pointer to validation features matrix\n",
    "    d = get_pointer(matrices[\"valid\"][\"y\"]),      # pointer to validation response matrix\n",
    "    e = nada_pointer                              # pointer to weight column (not using in this case)\n",
    ")\n",
    "\n",
    "# show the summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other things you can do with H2O4GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clustering with K-means\n",
    "\n",
    "See [kmeans.py](https://github.com/h2oai/h2o4gpu/blob/master/src/interface_py/h2o4gpu/solvers/kmeans.py) for more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "         INCEARN ROOMS BEDROOMS PHONE VEHICLES  AGE CLUSTER\n",
       "9900      152777.4   5.0      4.0   2.0      4.0 47.0       1\n",
       "9901      152777.4   8.0      5.0   2.0      2.0 58.0       1\n",
       "9902      152777.4   8.0      4.0   2.0      2.0 59.0       1\n",
       "9903      152777.4   9.0      5.0   2.0      2.0 38.0       1\n",
       "9904      152777.4   6.0      4.0   2.0      2.0 47.0       1\n",
       "9905      152777.4   9.0      5.0   2.0      2.0 72.0       1\n",
       "9906      152777.4   9.0      5.0   2.0      3.0 57.0       1\n",
       "9907      152777.4   9.0      5.0   2.0      2.0 59.0       1\n",
       "9908      152777.4   3.0      2.0   2.0      9.0 47.0       1\n",
       "9909      152777.4   7.0      4.0   2.0      2.0 42.0       1\n",
       "9910      152777.4   7.0      4.0   2.0      2.0 47.0       1\n",
       "9911      152777.4   9.0      6.0   2.0      2.0 61.0       1\n",
       "9912      152777.4   5.0      4.0   2.0      2.0 33.0       1\n",
       "9913      152777.4   7.0      4.0   2.0      2.0 52.0       1\n",
       "9914    154814.432   2.0      2.0   2.0      3.0 25.0       1\n",
       "9915     157869.98   8.0      5.0   2.0      2.0 54.0       1\n",
       "9916     157869.98   9.0      5.0   2.0      2.0 36.0       1\n",
       "9917    158888.496   3.0      3.0   2.0      2.0 71.0       1\n",
       "9918    158888.496   9.0      5.0   2.0      2.0 45.0       1\n",
       "9919 159908.030516   9.0      4.0   2.0      2.0 42.0       1\n",
       "9920     162962.56   9.0      6.0   2.0      2.0 44.0       1\n",
       "9921     162962.56   6.0      4.0   2.0      3.0 50.0       1\n",
       "9922     162962.56   9.0      6.0   2.0      4.0 54.0       1\n",
       "9923     162962.56   6.0      5.0   2.0      2.0 31.0       1\n",
       "9924     162962.56   3.0      3.0   2.0      1.0 37.0       1\n",
       "9925     162962.56   9.0      4.0   2.0      3.0 43.0       1\n",
       "9926    164999.592   6.0      4.0   2.0      1.0 67.0       1\n",
       "9927    164999.592   9.0      6.0   2.0      3.0 42.0       1\n",
       "9928    164999.592   9.0      5.0   2.0      6.0 51.0       1\n",
       "9929    164999.592   3.0      3.0   2.0      2.0 28.0       1\n",
       "9930    164999.592   6.0      3.0   2.0      2.0 57.0       1\n",
       "9931    164999.592   6.0      4.0   2.0      2.0 45.0       1\n",
       "9932    167036.624   6.0      4.0   2.0      2.0 50.0       1\n",
       "9933     168055.14   6.0      4.0   2.0      2.0 45.0       1\n",
       "9934     168055.14   9.0      5.0   2.0      3.0 50.0       1\n",
       "9935    172129.204   6.0      4.0   2.0      2.0 62.0       1\n",
       "9936     173147.72   9.0      6.0   2.0      1.0 42.0       1\n",
       "9937     173147.72   7.0      4.0   2.0      2.0 56.0       1\n",
       "9938     173147.72   1.0      1.0   2.0      1.0 36.0       1\n",
       "9939    174166.236   9.0      5.0   2.0      2.0 37.0       1\n",
       "9940    174166.236   8.0      5.0   2.0      4.0 52.0       1\n",
       "9941    174166.236   5.0      3.0   2.0      2.0 73.0       1\n",
       "9942    174166.236   9.0      6.0   2.0      3.0 57.0       1\n",
       "9943      178240.3   8.0      4.0   2.0      2.0 37.0       1\n",
       "9944      178240.3   7.0      4.0   2.0      2.0 32.0       1\n",
       "9945      178240.3   7.0      5.0   2.0      3.0 59.0       1\n",
       "9946     183332.88   7.0      4.0   2.0      2.0 47.0       1\n",
       "9947     183332.88   9.0      6.0   2.0      4.0 48.0       1\n",
       "9948    187406.944   9.0      6.0   2.0      4.0 48.0       1\n",
       "9949    187406.944   8.0      5.0   2.0      2.0 71.0       1\n",
       "9950     188425.46   9.0      5.0   2.0      2.0 44.0       1\n",
       "9951     188425.46   9.0      5.0   2.0      3.0 55.0       1\n",
       "9952    189443.976   9.0      6.0   2.0      3.0 54.0       1\n",
       "9953    190462.492   4.0      4.0   2.0      9.0 42.0       1\n",
       "9954    191481.008   8.0      4.0   2.0      2.0 51.0       1\n",
       "9955     193518.04   7.0      4.0   2.0      2.0 35.0       1\n",
       "9956     193518.04   8.0      5.0   2.0      4.0 56.0       1\n",
       "9957     193518.04   7.0      5.0   2.0      3.0 58.0       1\n",
       "9958      203703.2   5.0      4.0   2.0      1.0 52.0       1\n",
       "9959    207777.264   9.0      6.0   2.0      2.0 40.0       1\n",
       "9960    207777.264   8.0      5.0   2.0      5.0 52.0       1\n",
       "9961    230184.616   3.0      2.0   2.0      2.0 35.0       1\n",
       "9962    246480.872   6.0      4.0   2.0      2.0 59.0       4\n",
       "9963     290277.06   6.0      3.0   2.0      2.0 42.0       4\n",
       "9964    307591.832   9.0      4.0   2.0      3.0 46.0       4\n",
       "9965    318795.508   9.0      5.0   2.0      3.0 47.0       4\n",
       "9966 318796.526516   7.0      3.0   2.0      2.0 53.0       4\n",
       "9967    328980.668   4.0      3.0   2.0      1.0 50.0       4\n",
       "9968    328980.668   8.0      5.0   2.0      2.0 50.0       4\n",
       "9969    334073.248   9.0      5.0   2.0      2.0 44.0       4\n",
       "9970    338147.312   9.0      5.0   2.0      3.0 50.0       4\n",
       "9971    339165.828   4.0      3.0   2.0      1.0 37.0       4\n",
       "9972    343239.892   8.0      4.0   2.0      3.0 52.0       4\n",
       "9973    345276.924   8.0      4.0   2.0      2.0 46.0       4\n",
       "9974    345276.924   9.0      5.0   2.0      2.0 62.0       4\n",
       "9975    350369.504   9.0      6.0   2.0      3.0 50.0       4\n",
       "9976    350369.504   9.0      5.0   2.0      2.0 41.0       4\n",
       "9977    353425.052   9.0      6.0   2.0      3.0 61.0       4\n",
       "9978    354443.568   5.0      3.0   2.0      2.0 74.0       4\n",
       "9979    357499.116   9.0      6.0   2.0      2.0 56.0       4\n",
       "9980    357499.116   9.0      5.0   2.0      2.0 42.0       4\n",
       "9981    359536.148   7.0      4.0   2.0      3.0 37.0       4\n",
       "9982     361573.18   8.0      5.0   2.0      2.0 46.0       4\n",
       "9983     366665.76   9.0      5.0   2.0      6.0 53.0       4\n",
       "9984     366665.76   8.0      4.0   2.0      3.0 55.0       4"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# note: does not use gpu data currently, but does train on gpu\n",
    "\n",
    "# get the data as a numpy ndarray\n",
    "cpu_matrix = gdf.as_matrix()\n",
    "\n",
    "# set up the k-means model\n",
    "kmeans = h2o4gpu.KMeans(\n",
    "    n_clusters = 5,\n",
    "    n_gpus = 1,\n",
    "    max_iter = 1000\n",
    ")\n",
    "\n",
    "# fit and predict (can be broken up into separate `fit` and `predict` methods)\n",
    "predicted_clusters = kmeans.fit_predict(cpu_matrix)\n",
    "\n",
    "# copy the cluster results onto a new gdf as a new column called `CLUSTER`\n",
    "gdf_with_clusters = gdf.loc[:, [\"INCEARN\", \"ROOMS\", \"BEDROOMS\", \"PHONE\", \"VEHICLES\", \"AGE\"]].copy()\n",
    "gdf_with_clusters.add_column(\"CLUSTER\", predicted_clusters)\n",
    "\n",
    "# show the last 85 rows of results\n",
    "gdf_with_clusters.loc[9900:9985].head(85)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCA\n",
    "\n",
    "See [pcay.py](https://github.com/h2oai/h2o4gpu/blob/master/src/interface_py/h2o4gpu/solvers/pca.py) for more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "explained variance [  1.20293687e+09   2.44333391e+05   4.94523652e+02]\n",
      "explained variance ratio [ 0.06315957  0.01398424  0.01398268]\n"
     ]
    }
   ],
   "source": [
    "from h2o4gpu.solvers.pca import PCAH2O\n",
    "\n",
    "# reduce down to the top 3 dimensions\n",
    "pca = PCAH2O(\n",
    "    n_components = 3\n",
    ")\n",
    "\n",
    "# use `X` from the previous use case\n",
    "# recall that it is a numpy ndarray of the input data\n",
    "pca.fit(cpu_matrix)\n",
    "\n",
    "# components\n",
    "# print(\"components\", pca.components_)\n",
    "\n",
    "# explained variance\n",
    "print(\"explained variance\", pca.explained_variance_)\n",
    "\n",
    "# explained variance ratio\n",
    "print(\"explained variance ratio\", pca.explained_variance_ratio_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regression via XGBoost\n",
    "\n",
    "See [xgboost.py](https://github.com/h2oai/h2o4gpu/blob/master/src/interface_py/h2o4gpu/solvers/xgboost.py) for more, including classification classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running h2o4gpu GradientBoostingRegressor\n",
      "[  6797.90087891   3378.71459961   9183.80957031  16129.484375\n",
      "  14172.34765625  15765.94824219  15628.46289062  14027.58789062\n",
      "  18759.87304688  18161.1796875   13734.5078125   18248.9921875\n",
      "  14172.34765625  17803.74023438  16812.0625      14660.29882812\n",
      "  19444.0390625   18712.04492188   6858.76806641  17068.14453125]\n"
     ]
    }
   ],
   "source": [
    "from h2o4gpu import GradientBoostingRegressor\n",
    "\n",
    "# ensure that we use the h2o4gpu backend (not sklearn)\n",
    "xgb = GradientBoostingRegressor(backend = \"h2o4gpu\")\n",
    "\n",
    "# convert input data from gdf to cpu matrices (numpy ndarrays)\n",
    "cpu_matrices = {\n",
    "    \"train\": {\n",
    "        \"x\": gdfs[\"train\"].as_matrix(columns=gdf.columns[1:]),\n",
    "        \"y\": gdfs[\"train\"].as_matrix(columns=[gdf.columns[0]]).flatten()\n",
    "    },\n",
    "    \"test\": {\n",
    "        \"x\": gdfs[\"valid\"].as_matrix(columns=gdf.columns[1:]),\n",
    "        \"y\": gdfs[\"valid\"].as_matrix(columns=[gdf.columns[0]]).flatten()\n",
    "    }\n",
    "}\n",
    "\n",
    "# set the base parameters\n",
    "num_rounds = 10\n",
    "xgb_params = {\n",
    "    \"learning_rate\": 0.1,\n",
    "    \"n_estimators\": 100,\n",
    "    \"subsample\": 1.0,\n",
    "    \"n_gpus\": 1\n",
    "}\n",
    "xgb.set_params(**xgb_params)\n",
    "\n",
    "# fit the model\n",
    "xgb.fit(X = cpu_matrices[\"train\"][\"x\"], y = cpu_matrices[\"train\"][\"y\"])\n",
    "\n",
    "# predict based upon test values\n",
    "xgb_predictions = xgb.model.predict(cpu_matrices[\"test\"][\"x\"])\n",
    "\n",
    "# show the first 20 results\n",
    "print(xgb_predictions[0:20])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Additional H2O4GPU Resources\n",
    "\n",
    "* [Solvers (code)](https://github.com/h2oai/h2o4gpu/tree/master/src/interface_py/h2o4gpu/solvers)\n",
    "* [Python examples](https://github.com/h2oai/h2o4gpu/tree/master/examples/py)\n",
    "* [Tests (useful for examples)](https://github.com/h2oai/h2o4gpu/tree/master/tests_open)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
